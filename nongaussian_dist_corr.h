#ifndef NONGAUSSIAN_DIST_CORR_H_
#define NONGAUSSIAN_DIST_CORR_H_

//#include <boost/numeric/conversion/cast.hpp>
#include <gsl/gsl_cdf.h>
#include <gsl/gsl_randist.h>
#include <gsl/gsl_rng.h>
#include <asserts.h>
#include <kernel.h>
#include <nongaussian_reg.h>
#include <nl_dgp.h>


#define CHUNK 1

using namespace std;

class NGDist_corr {
	public:
		NGDist_corr(){  }; //default constructor
		~NGDist_corr () { };//default destructor
	    //calculate the test statistic for two bivariate processes. INPUT: Tx1 data vectors (data_X and data_Y), a truncation lag (TL),
        //a lag-smoothing bandwidth (lag_smooth), the integral of the quartic polynomial of a kernel (kernel_QRSum), 6x1 vectors of AR coefficients (alpha_X and alpha_Y),
        //vectors of random errors (epsilon_t, epsilon_s, eta_t and eta_s) generated by gen_RAN (epsilon, eta, delta, 0., 0, rseed) with random seeds (rseed),
        //an exponent for the Euclidean distance (expn in (1,2)), a kernel weight (kernel_k) and a condition mean function (cmean).
        //OUTPUT: a double number.
        template <double kernel_k (double ), void cmean (double &, double &, const Matrix &, const Matrix &, const Matrix &, const Matrix &)>
        static double do_Test (const Matrix &data_X, const Matrix &data_Y, int TL, int lag_smooth, double kernel_QRSum, const Matrix &alpha_X,
                               const Matrix &alpha_Y, const Matrix &epsilon_t, const Matrix &epsilon_s, const Matrix &eta_t, const Matrix &eta_s,
							   const double expn);
		//calculate the test statistic for a univariate process and a bivariate process. INPUT: Tx1 data vectors (data_X, data_Y1, and data_Y2), a truncation lag (TL),
        //a lag-smoothing bandwidth (lag_smooth), the integral of the quartic polynomial of a kernel (kernel_QRSum), A 6x1 vector of coefficients for X (alpha_X),
        //a 6x2 matrix of coefficients for Y1 and Y2 (alpha_Y), Nx1 vectors of random errors (epsilon_t, epsilon_s, eta1_t, eta1_s, eta2_t and eta2_s) generated by
        //gen_RAN (epsilon, eta1, eta2, delta, 0., 0., 0, rseed) with random seeds (rseed), an exponent for the Euclidean distance (expn in (1,2)),
		//a kernel weight (kernel_k), an error-generating process (gen_RAN), and a condition mean function (cmean). OUTPUT: a double number.
        template <double kernel_k (double ), void cmean (double &, double &, double &, const Matrix &, const Matrix &, const Matrix &, const Matrix &)>
        static double do_Test (const Matrix &data_X, const Matrix &data_Y1, const Matrix &data_Y2, int TL, int lag_smooth, double kernel_QRSum,
                               const Matrix &alpha_X, const Matrix &alpha_Y, const Matrix &epsilon_t, const Matrix &epsilon_s, const Matrix &eta1_t,
							   const Matrix &eta1_s, const Matrix &eta2_t, const Matrix &eta2_s, const double expn);
		//calculate the bootstrap test statistics for a univariate process and a bivariate process. INPUT: Tx1 data vectors (data_X, data_Y1, and data_Y2),
		//a truncation lag (TL), a lag-smoothing bandwidth (lag_smooth), the integral of the quartic polynomial of a kernel (kernel_QRSum), A 6x1 vector of coefficients for X (alpha_X),
		//a 6x2 matrix of coefficients for Y1 and Y2 (alpha_Y), Nx1 vectors of random errors (epsilon_t, epsilon_s, eta1_t, eta1_s, eta2_t and eta2_s) generated by
		//gen_RAN (epsilon, eta1, eta2, delta, 0., 0., 0, rseed) with random seeds (rseed), num_BxT matrices of auxiliary random variables (xi_x and xi_y),
		//an exponent for the Euclidean distance (expn in (1,2)), a kernel weight (kernel_k), an error-generating process (gen_RAN), and a condition mean function (cmean).
		//OUTPUT: a bootstrap p-value, a value of the statistic (cstat), and a vector of bootstrap statistics (cstat_bootstrap)
		template <double kernel_k (double ), void cmean (double &, double &, double &, const Matrix &, const Matrix &, const Matrix &, const Matrix &)>
		static double calcul_Pvalue (double &cstat, Matrix &cstat_bootstrap, const Matrix &data_X, const Matrix &data_Y1, const Matrix &data_Y2, int TL, int lag_smooth,
												   const Matrix &alpha_X, const Matrix &alpha_Y, const Matrix &epsilon_t, const Matrix &epsilon_s, const Matrix &eta1_t, const Matrix &eta1_s,
												   const Matrix &eta2_t, const Matrix &eta2_s, const Matrix & xi_x, const Matrix &xi_y, const double expn);
		//calculate the distance-correlation-based test statistic for testing the independence of two vector-valued time series, where each is modeled through a flexible VAR model with B-splines
		//(which is then estimated using the adaptive group LASSO). INPUT: a T0 by N_x matrix of data on the response of the first multivariate process (X), a T0 by N_y matrix of data on
		//the response of the second multivariate process (Y), m*L_x*N_x by T0  and m*L_y*N_y by T0 matrices of B-spline basis functions evaluated at all the data points (BS_x and BS_y),
		//m*L_x*N_x by N_x and m*L_y*N_y by N_y matrices of B-spline coefficients (beta_x and beta_y), and an exponent for the distance correlation (expn).
		//OUTPUT: a double type value of the test statistic.
		template <double kernel_k (double )>
		static double do_Test (const Matrix &X, const Matrix &Y, const Matrix &BS_x, const Matrix &BS_y, const Matrix &beta_x, const Matrix &beta_y, const int lag_smooth,
									    const double expn);
		//calculate the bootstrap test statistics for two multivariate GARCH processes. INPUT: T-row matrices of data (X and Y), matrices of conditional means (cmean_X and cmean_Y),
		//matrices of the sqrts of conditional variances and covariances (csigma_X and csigma_Y), matrices of GARCH residuals (resid_X and resid_Y), a lag-smoothing bandwidth (lag_smooth),
		//num_BxT matrices of auxiliary random variables (xi_x and xi_y), an exponent for the Euclidean distance (expn in (1,2)), a kernel weight (kernel_k).
		//OUTPUT: a bootstrap p-value, a value of the statistic (cstat), and a vector of bootstrap statistics (cstat_bootstrap)
		template <double kernel_k (double )>
		static double calcul_Pvalue (double &cstat, Matrix &cstat_bootstrap, const Matrix &X, const Matrix &Y, const Matrix &cmean_X, const Matrix &cmean_Y,
												const Matrix &csigma_X, const Matrix &csigma_Y, const Matrix &resid_X, const Matrix &resid_Y, const int lag_smooth,
												const Matrix & xi_x, const Matrix &xi_y, const double expn);

		//integrate quadratic and quartic functions of a kernel weight
        template <double kernel_k (double )>
        static void integrate_Kernel (double &kernel_QDSum, double &kernel_QRSum);
};

//integrate quadratic and quartic functions of a kernel weight
template <double kernel_k (double )>
void NGDist_corr::integrate_Kernel (double &kernel_QDSum, double &kernel_QRSum) {
	double x = 0.;
	kernel_QDSum = 0.;
	kernel_QRSum = 0.;
	int t = 1, N = 500000;
	gsl_rng *r = nullptr;
    const gsl_rng_type * gen;//random number generator
    gsl_rng_env_setup();
    gen = gsl_rng_taus;
    r = gsl_rng_alloc(gen);
    gsl_rng_set(r, 3525364362);
	while (t <= N) {
		x =  60 * gsl_rng_uniform(r) - 30; //integral over the range [-30, 30]
		kernel_QDSum += 60 * ((double) 1/N) * pow(kernel_k (x), 2.);
		kernel_QRSum += 60 * ((double) 1/N) * pow(kernel_k (x), 4.);
		++t;
	}
	gsl_rng_free (r);
}

//calculate the test statistic for two bivariate processes. INPUT: Tx1 data vectors (data_X and data_Y), a truncation lag (TL),
//a lag-smoothing bandwidth (lag_smooth), the integral of the quartic polynomial of a kernel (kernel_QRSum), 6x1 vectors of AR coefficients (alpha_X and alpha_Y),
//vectors of random errors (epsilon_t, epsilon_s, eta_t and eta_s) generated by gen_RAN (epsilon, eta, delta, 0., 0, rseed) with random seeds (rseed),
//an exponent for the Euclidean distance (expn in (1,2)), a kernel weight (kernel_k) and a condition mean function (cmean).
//OUTPUT: a double number.
template <double kernel_k (double ), void cmean (double &, double &, const Matrix &, const Matrix &, const Matrix &, const Matrix &)>
double NGDist_corr::do_Test (const Matrix &data_X, const Matrix &data_Y, int TL, int lag_smooth, double kernel_QRSum, const Matrix &alpha_X,
                             const Matrix &alpha_Y, const Matrix &epsilon_t, const Matrix &epsilon_s, const Matrix &eta_t, const Matrix &eta_s,
							 const double expn) {
    auto t = 1, s = 1, tau = 1, lag = 0;
    auto T = data_X.nRow();
    ASSERT(T == data_Y.nRow()); //check if matrices data_X and data_Y are of the same size
    Matrix xy_t(2,1), xy_s(2,1), lag_t1(2,1), lag_t2(2,1), lag_s1(2,1), lag_s2(2,1), var_U_x(T-TL,T-TL), var_U_y(T-TL,T-TL);
	#pragma omp parallel for default(shared) schedule(dynamic,CHUNK) private(t,s) firstprivate(xy_t,xy_s,lag_t1,lag_t2,lag_s1,lag_s2)
	for (t = TL+1; t <= T; t++) {
		xy_t(1) = data_X(t);
		xy_t(2) = data_Y(t);
		lag_t1(1) = data_X(t-1);
		lag_t1(2) = data_Y(t-1);
		lag_t2(1) = data_X(t-2);
		lag_t2(2) = data_Y(t-2);
		for (s = TL+1; s <= T; s++) {
			if (s >= t) {
				xy_s(1) = data_X(s);
				xy_s(2) = data_Y(s);
				lag_s1(1) = data_X(s-1);
				lag_s1(2) = data_Y(s-1);
				lag_s2(1) = data_X(s-2);
				lag_s2(2) = data_Y(s-2);
				NGReg::var_U_ts<cmean> (var_U_x(t-TL,s-TL), var_U_y(t-TL,s-TL), xy_t, xy_s, lag_t1, lag_t2, lag_s1, lag_s2, alpha_X, alpha_Y, epsilon_t,
				                        epsilon_s, eta_t, eta_s, expn); //calculate U_{t,s}^{(x)} and U_{t,s}^{(y)}
				var_U_x(s-TL, t-TL) = var_U_x(t-TL, s-TL); //symmetric matrices
			    var_U_y(s-TL, t-TL) = var_U_y(t-TL, s-TL);
		    }
			//cout << var_U_y(t-TL, s-TL) << " , ";
		}
		//cout << "\n";
	}
	double aVar = 0.;
	for (s = TL+1; s <= T; s++) {
		for (t = s+1; t <= T; t++) {
			aVar += ((double) 1/pow(T-TL, 2.)) * pow(var_U_x(t-TL, s-TL) * var_U_y(t-TL, s-TL), 2.);
		}
	}
	double weight = 0., sum1 = 0., sum2 = 0., sum3 = 0., sum4 = 0., cov = 0., sum = 0.;
	//prod_Var = var(X, TL, alpha(1), beta(1), lambda(1), sigma(1)) * var(Y, TL, alpha(2), beta(2), lambda(2), sigma(2));//calculate product of distance variances
	//cout << "product of variances = " << prod_Var << endl;
	#pragma omp parallel for default(shared) reduction (+:sum) schedule(dynamic,CHUNK) firstprivate(weight,sum1,sum2,sum3,sum4,cov) private(lag,t,s,tau)
	for (lag = 1-T+TL; lag <= T-TL-1; lag++) {
        if (lag == 0) weight = 1.;
        else weight = kernel_k ((double) lag/lag_smooth);
        if ((weight > 0.0001) || (weight < -0.0001)) {
        	if (lag >= 0) {
        	    sum1 = 0.;
        	    sum2 = 0.;
        	    sum3 = 0.;
        	    sum4 = 0.;
        	    for (t = lag+TL+1; t <= T; t++) {
			        for (s = lag+TL+1; s <= T; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t-TL, s-TL) * var_U_y(t-TL-lag, s-TL-lag);
				        }
				        sum3 += var_U_x(t-TL, s-TL);
				        sum4 += var_U_y(t-TL-lag, s-TL-lag) ;
				        for (tau = lag+TL+1; tau <= T; tau++) {
					        sum2 += 2 * var_U_x(t-TL, s-TL) * var_U_y(tau-TL-lag, s-TL-lag);
				        }
				    }
			    }
			    cov = ((double) 1/pow(T-TL-lag, 2.)) * sum1 - ((double) 1/pow(T-TL-lag, 3.)) * sum2 + ((double) 1/pow(T-TL-lag, 4.)) * sum3 * sum4;
		    }
		    else {
				sum1 = 0.;
				sum2 = 0.;
				sum3 = 0.;
				sum4 = 0.;
			    for (t = TL+1-lag; t <= T; t++) {
			        for (s = TL+1-lag; s <= T; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t-TL+lag, s-TL+lag) * var_U_y(t-TL, s-TL);
				        }
				        sum3 += var_U_x(t-TL+lag, s-TL+lag);
				        sum4 += var_U_y(t-TL, s-TL);
				        for (tau = TL+1-lag; tau <= T; tau++) {
					        sum2 += 2 * var_U_x(t-TL+lag, s-TL+lag) * var_U_y(t-TL, tau-TL);
				        }
			        }
		        }
			    cov = ((double) 1/pow(T-TL+lag, 2.)) * sum1 - ((double) 1/pow(T-TL+lag, 3.)) * sum2 + ((double) 1/pow(T-TL+lag, 4.)) * sum3 * sum4;
		    }
		    sum += (T-TL) * pow(weight, 2.) * cov;
            //cout << "counting lags: " << lag << endl;
        }
	}
	//cout << "sum = " << sum << endl;
	//return (sum - lag_smooth * kernel_QDSum * prod_Var) / (2 * sqrt(lag_smooth * kernel_QRSum * aVar));
	return sum / (2 * sqrt(lag_smooth * kernel_QRSum * aVar));
}

//calculate the test statistic for a univariate process and a bivariate process. INPUT: Tx1 data vectors (data_X, data_Y1, and data_Y2), a truncation lag (TL),
//a lag-smoothing bandwidth (lag_smooth), the integral of the quartic polynomial of a kernel (kernel_QRSum), A 6x1 vector of coefficients for X (alpha_X),
//a 6x2 matrix of coefficients for Y1 and Y2 (alpha_Y), Nx1 vectors of random errors (epsilon_t, epsilon_s, eta1_t, eta1_s, eta2_t and eta2_s) generated by
//gen_RAN (epsilon, eta1, eta2, delta, 0., 0., 0, rseed) with random seeds (rseed), an exponent for the Euclidean distance (expn in (1,2)),
//a kernel weight (kernel_k), an error-generating process (gen_RAN), and a condition mean function (cmean).
//OUTPUT: a double number.
template <double kernel_k (double ), void cmean (double &, double &, double &, const Matrix &, const Matrix &, const Matrix &, const Matrix &)>
double NGDist_corr::do_Test (const Matrix &data_X, const Matrix &data_Y1, const Matrix &data_Y2, int TL, int lag_smooth, double kernel_QRSum,
                             const Matrix &alpha_X, const Matrix &alpha_Y, const Matrix &epsilon_t, const Matrix &epsilon_s, const Matrix &eta1_t,
							 const Matrix &eta1_s, const Matrix &eta2_t, const Matrix &eta2_s, const double expn) {
    auto t = 1, s = 1, tau = 1, lag = 0;
    auto T = data_X.nRow();
    ASSERT(T == data_Y1.nRow() && T == data_Y2.nRow()); //check if data matrices are of the same size
    Matrix xy_t(3,1), xy_s(3,1), lag_t1(3,1), lag_t2(3,1), lag_s1(3,1), lag_s2(3,1), var_U_x(T-TL,T-TL), var_U_y(T-TL,T-TL);
	#pragma omp parallel for default(shared) schedule(dynamic,CHUNK) private(t,s) firstprivate(xy_t,xy_s,lag_t1,lag_t2,lag_s1,lag_s2)
	for (t = TL+1; t <= T; t++) {
		xy_t(1) = data_X(t);
		xy_t(2) = data_Y1(t);
		xy_t(3) = data_Y2(t);
		lag_t1(1) = data_X(t-1);
		lag_t1(2) = data_Y1(t-1);
		lag_t1(3) = data_Y2(t-1);
		lag_t2(1) = data_X(t-2);
		lag_t2(2) = data_Y1(t-2);
		lag_t2(3) = data_Y2(t-2);
		for (s = TL+1; s <= T; s++) {
			if (s >= t) {
				xy_s(1) = data_X(s);
				xy_s(2) = data_Y1(s);
				xy_s(3) = data_Y2(s);
				lag_s1(1) = data_X(s-1);
				lag_s1(2) = data_Y1(s-1);
				lag_s1(3) = data_Y2(s-1);
				lag_s2(1) = data_X(s-2);
				lag_s2(2) = data_Y1(s-2);
				lag_s2(3) = data_Y2(s-2);
				NGReg::var_U_ts<cmean> (var_U_x(t-TL,s-TL), var_U_y(t-TL,s-TL), xy_t, xy_s, lag_t1, lag_t2, lag_s1, lag_s2, alpha_X, alpha_Y,
				                        epsilon_t, epsilon_s, eta1_t, eta1_s, eta2_t, eta2_s, expn); //calculate U_{t,s}^{(x)} and U_{t,s}^{(y)}
				var_U_x(s-TL, t-TL) = var_U_x(t-TL, s-TL); //symmetric matrices
			    var_U_y(s-TL, t-TL) = var_U_y(t-TL, s-TL);
			    //cout << var_U_y(t-TL, s-TL) << " , ";
		    }
		}
		//cout << "\n";
	}
	double aVar = 0.;
	for (s = TL+1; s <= T; s++) {
		for (t = s+1; t <= T; t++) {
			aVar += ((double) 1/pow(T-TL, 2.)) * pow(var_U_x(t-TL, s-TL) * var_U_y(t-TL, s-TL), 2.);
		}
	}
	double weight = 0., sum1 = 0., sum2 = 0., sum3 = 0., sum4 = 0., cov = 0., sum = 0.;
	//prod_Var = var(X, TL, alpha(1), beta(1), lambda(1), sigma(1)) * var(Y, TL, alpha(2), beta(2), lambda(2), sigma(2));//calculate product of distance variances
	//cout << "product of variances = " << prod_Var << endl;
	#pragma omp parallel for default(shared) reduction (+:sum) schedule(dynamic,CHUNK) firstprivate(weight,sum1,sum2,sum3,sum4,cov) private(lag,t,s,tau)
	for (lag = 1-T+TL; lag <= T-TL-1; lag++) {
        if (lag == 0) weight = 1.;
        else weight = kernel_k ((double) lag/lag_smooth);
        if ((weight > 0.0001) || (weight < -0.0001)) {
        	if (lag >= 0) {
        	    sum1 = 0.;
        	    sum2 = 0.;
        	    sum3 = 0.;
        	    sum4 = 0.;
        	    for (t = lag+TL+1; t <= T; t++) {
			        for (s = lag+TL+1; s <= T; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t-TL, s-TL) * var_U_y(t-TL-lag, s-TL-lag);
				        }
				        sum3 += var_U_x(t-TL, s-TL);
				        sum4 += var_U_y(t-TL-lag, s-TL-lag) ;
				        for (tau = lag+TL+1; tau <= T; tau++) {
					        sum2 += 2 * var_U_x(t-TL, s-TL) * var_U_y(tau-TL-lag, s-TL-lag);
				        }
				    }
			    }
			    cov = ((double) 1/pow(T-TL-lag, 2.)) * sum1 - ((double) 1/pow(T-TL-lag, 3.)) * sum2 + ((double) 1/pow(T-TL-lag, 4.)) * sum3 * sum4;
		    }
		    else {
			    sum1 = 0.;
        	    sum2 = 0.;
        	    sum3 = 0.;
        	    sum4 = 0.;
			    for (t = TL+1-lag; t <= T; t++) {
			        for (s = TL+1-lag; s <= T; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t-TL+lag, s-TL+lag) * var_U_y(t-TL, s-TL);
				        }
				        sum3 += var_U_x(t-TL+lag, s-TL+lag);
				        sum4 += var_U_y(t-TL, s-TL);
				        for (tau = TL+1-lag; tau <= T; tau++) {
					        sum2 += 2 * var_U_x(t-TL+lag, s-TL+lag) * var_U_y(t-TL, tau-TL);
				        }
			        }
		        }
			    cov = ((double) 1/pow(T-TL+lag, 2.)) * sum1 - ((double) 1/pow(T-TL+lag, 3.)) * sum2 + ((double) 1/pow(T-TL+lag, 4.)) * sum3 * sum4;
		    }
		    sum += (T-TL) * pow(weight, 2.) * cov;
            //cout << "counting lags: " << lag << endl;
        }
	}
	//cout << "sum = " << sum << endl;
	//return (sum - lag_smooth * kernel_QDSum * prod_Var) / (2 * sqrt(lag_smooth * kernel_QRSum * aVar));
	return sum / (2 * sqrt(lag_smooth * kernel_QRSum * aVar));
}

//calculate the bootstrap test statistics for a univariate process and a bivariate process. INPUT: Tx1 data vectors (data_X, data_Y1, and data_Y2),
//a number of bootstrap samples (num_B), a truncation lag (TL), a lag-smoothing bandwidth (lag_smooth), the integral of the quartic polynomial of a kernel (kernel_QRSum),
//A 6x1 vector of coefficients for X (alpha_X), a 6x2 matrix of coefficients for Y1 and Y2 (alpha_Y), Nx1 vectors of random errors (epsilon_t, epsilon_s, eta1_t, eta1_s, eta2_t and eta2_s)
//generated by gen_RAN (epsilon, eta1, eta2, delta, 0., 0., 0, rseed) with random seeds (rseed), num_BxT matrices of auxiliary random variables (xi_x and xi_y),
//an exponent for the Euclidean distance (expn in (1,2)), a kernel weight (kernel_k), an error-generating process (gen_RAN), and a condition mean function (cmean).
//OUTPUT: a bootstrap p-value, a value of the statistic (cstat), and a vector of bootstrap statistics (cstat_bootstrap)
template <double kernel_k (double ), void cmean (double &, double &, double &, const Matrix &, const Matrix &, const Matrix &, const Matrix &)>
double NGDist_corr::calcul_Pvalue (double &cstat, Matrix &cstat_bootstrap, const Matrix &data_X, const Matrix &data_Y1, const Matrix &data_Y2, int TL, int lag_smooth,
												   const Matrix &alpha_X, const Matrix &alpha_Y, const Matrix &epsilon_t, const Matrix &epsilon_s, const Matrix &eta1_t, const Matrix &eta1_s,
												   const Matrix &eta2_t, const Matrix &eta2_s, const Matrix & xi_x, const Matrix &xi_y, const double expn) {
    auto t = 1, s = 1, tau = 1, lag = 0, i = 1;
    auto T = data_X.nRow();
    auto num_B = xi_x.nRow();
    ASSERT (num_B == xi_y.nRow()); //check for the size consistency of matrices of auxiliary random variables
    ASSERT (T == data_Y1.nRow() && T == data_Y2.nRow() && T == xi_x.nCol() && T == xi_y.nCol()); //check if data matrices are of the same size
    Matrix xy_t(3,1), xy_s(3,1), lag_t1(3,1), lag_t2(3,1), lag_s1(3,1), lag_s2(3,1), var_U_x(T-TL,T-TL), var_U_y(T-TL,T-TL);
	#pragma omp parallel for default(shared) schedule(dynamic,CHUNK) private(t,s) firstprivate(xy_t,xy_s,lag_t1,lag_t2,lag_s1,lag_s2)
	for (t = TL+1; t <= T; t++) {
		xy_t(1) = data_X(t);
		xy_t(2) = data_Y1(t);
		xy_t(3) = data_Y2(t);
		lag_t1(1) = data_X(t-1);
		lag_t1(2) = data_Y1(t-1);
		lag_t1(3) = data_Y2(t-1);
		lag_t2(1) = data_X(t-2);
		lag_t2(2) = data_Y1(t-2);
		lag_t2(3) = data_Y2(t-2);
		for (s = TL+1; s <= T; s++) {
			if (s >= t) {
				xy_s(1) = data_X(s);
				xy_s(2) = data_Y1(s);
				xy_s(3) = data_Y2(s);
				lag_s1(1) = data_X(s-1);
				lag_s1(2) = data_Y1(s-1);
				lag_s1(3) = data_Y2(s-1);
				lag_s2(1) = data_X(s-2);
				lag_s2(2) = data_Y1(s-2);
				lag_s2(3) = data_Y2(s-2);
				NGReg::var_U_ts<cmean> (var_U_x(t-TL,s-TL), var_U_y(t-TL,s-TL), xy_t, xy_s, lag_t1, lag_t2, lag_s1, lag_s2, alpha_X, alpha_Y,
				                        epsilon_t, epsilon_s, eta1_t, eta1_s, eta2_t, eta2_s, expn); //calculate U_{t,s}^{(x)} and U_{t,s}^{(y)}
				var_U_x(s-TL, t-TL) = var_U_x(t-TL, s-TL); //symmetric matrices
			    var_U_y(s-TL, t-TL) = var_U_y(t-TL, s-TL);
			    //cout << var_U_y(t-TL, s-TL) << " , ";
		    }
		}
		//cout << "\n";
	}

	double weight = 0., sum1 = 0., sum2 = 0., sum3 = 0., sum4 = 0., cov = 0., sum = 0.;
	//prod_Var = var(X, TL, alpha(1), beta(1), lambda(1), sigma(1)) * var(Y, TL, alpha(2), beta(2), lambda(2), sigma(2));//calculate product of distance variances
	//cout << "product of variances = " << prod_Var << endl;

	/* calculate the centered quantity */
	#pragma omp parallel for default(shared) reduction (+:sum) schedule(dynamic,CHUNK) firstprivate(weight,sum1,sum2,sum3,sum4,cov) private(lag,t,s,tau)
	for (lag = 1-T+TL; lag <= T-TL-1; lag++) {
        if (lag == 0) weight = 1.;
        else weight = kernel_k ((double) lag/lag_smooth);
        if ((weight > 0.0001) || (weight < -0.0001)) {
        	if (lag >= 0) {
        	    sum1 = 0.;
        	    sum2 = 0.;
        	    sum3 = 0.;
        	    sum4 = 0.;
        	    for (t = lag+TL+1; t <= T; t++) {
			        for (s = lag+TL+1; s <= T; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t-TL, s-TL) * var_U_y(t-TL-lag, s-TL-lag);
				        }
				        sum3 += var_U_x(t-TL, s-TL);
				        sum4 += var_U_y(t-TL-lag, s-TL-lag) ;
				        for (tau = lag+TL+1; tau <= T; tau++) {
					        sum2 += 2 * var_U_x(t-TL, s-TL) * var_U_y(tau-TL-lag, s-TL-lag);
				        }
				    }
			    }
			    cov = ((double) 1/pow(T-TL-lag, 2.)) * sum1 - ((double) 1/pow(T-TL-lag, 3.)) * sum2 + ((double) 1/pow(T-TL-lag, 4.)) * sum3 * sum4;
		    }
		    else {
			    sum1 = 0.;
        	    sum2 = 0.;
        	    sum3 = 0.;
        	    sum4 = 0.;
			    for (t = TL+1-lag; t <= T; t++) {
			        for (s = TL+1-lag; s <= T; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t-TL+lag, s-TL+lag) * var_U_y(t-TL, s-TL);
				        }
				        sum3 += var_U_x(t-TL+lag, s-TL+lag);
				        sum4 += var_U_y(t-TL, s-TL);
				        for (tau = TL+1-lag; tau <= T; tau++) {
					        sum2 += 2 * var_U_x(t-TL+lag, s-TL+lag) * var_U_y(t-TL, tau-TL);
				        }
			        }
		        }
			    cov = ((double) 1/pow(T-TL+lag, 2.)) * sum1 - ((double) 1/pow(T-TL+lag, 3.)) * sum2 + ((double) 1/pow(T-TL+lag, 4.)) * sum3 * sum4;
		    }
		    sum += (T-TL) * pow(weight, 2.) * cov;
            //cout << "counting lags: " << lag << endl;
        }
	}
	//cout << "sum = " << sum << endl;
	//return (sum - lag_smooth * kernel_QDSum * prod_Var) / (2 * sqrt(lag_smooth * kernel_QRSum * aVar));
	cstat =  ((double) sum / sqrt(lag_smooth));
	//cout << "the value of the statistics = " << cstat << endl;

	/* calculate bootstrap centered quantities */
	#pragma omp parallel for default(shared) reduction (+:sum) schedule(dynamic,CHUNK) firstprivate(weight,sum1,sum2,sum3,sum4,cov) private(i,lag,t,s,tau)
	for (i = 1; i <= num_B; i++) {
		cov = 0.; //reset the value of 'cov' and 'sum' to zeros in each bootstrap iteration
		sum = 0.;

		for (lag = 1-T+TL; lag <= T-TL-1; lag++) {
			if (lag == 0) weight = 1.;
			else weight = kernel_k ((double) lag/lag_smooth);
			if ((weight > 0.0001) || (weight < -0.0001)) {
				if (lag >= 0) {
					sum1 = 0.;
					sum2 = 0.;
					sum3 = 0.;
					sum4 = 0.;
					for (t = lag+TL+1; t <= T; t++) {
						for (s = lag+TL+1; s <= T; s++) {
							if (t != s) {
								sum1 += xi_x(i, t-TL) * xi_x(i, s-TL) * var_U_x(t-TL, s-TL) * var_U_y(t-TL-lag, s-TL-lag) * xi_y(i, t-TL-lag) * xi_y(i, s-TL-lag);
							}
							sum3 += xi_x(i, t-TL) * xi_x(i, s-TL) * var_U_x(t-TL, s-TL);
							sum4 += xi_y(i, t-TL-lag) * xi_y(i, s-TL-lag) * var_U_y(t-TL-lag, s-TL-lag) ;
							for (tau = lag+TL+1; tau <= T; tau++) {
								sum2 += 2 * xi_x(i, t-TL) * xi_x(i, s-TL) * var_U_x(t-TL, s-TL) * var_U_y(tau-TL-lag, s-TL-lag) * xi_y(i, tau-TL-lag) * xi_y(i, s-TL-lag);
							}
						}
					}
					cov = ((double) 1/pow(T-TL-lag, 2.)) * sum1 - ((double) 1/pow(T-TL-lag, 3.)) * sum2 + ((double) 1/pow(T-TL-lag, 4.)) * sum3 * sum4;
				}
				else {
					sum1 = 0.;
					sum2 = 0.;
					sum3 = 0.;
					sum4 = 0.;
					for (t = TL+1-lag; t <= T; t++) {
						for (s = TL+1-lag; s <= T; s++) {
							if (t != s) {
								sum1 += xi_x(i, t-TL+lag) * xi_x(i, s-TL+lag) * var_U_x(t-TL+lag, s-TL+lag) * var_U_y(t-TL, s-TL) * xi_y(i, t-TL) * xi_y(i, s-TL);
							}
							sum3 += xi_x(i, t-TL+lag) * xi_x(i, s-TL+lag) * var_U_x(t-TL+lag, s-TL+lag);
							sum4 += xi_y(i, t-TL) * xi_y(i, s-TL) * var_U_y(t-TL, s-TL);
							for (tau = TL+1-lag; tau <= T; tau++) {
								sum2 += 2 * xi_x(i, t-TL+lag) * xi_x(i, s-TL+lag) * var_U_x(t-TL+lag, s-TL+lag) * var_U_y(t-TL, tau-TL) * xi_y(i, t-TL) * xi_y(i, tau-TL);
							}
						}
					}
					cov = ((double) 1/pow(T-TL+lag, 2.)) * sum1 - ((double) 1/pow(T-TL+lag, 3.)) * sum2 + ((double) 1/pow(T-TL+lag, 4.)) * sum3 * sum4;
				}
				sum += (T-TL) * pow(weight, 2.) * cov;
				//cout << "counting lags: " << lag << endl;
			}
		}
		cstat_bootstrap(i) =  ((double) sum / sqrt(lag_smooth));
	}

	int count = 0;
	for (i = 1; i <= num_B; i++) {
		if (cstat_bootstrap(i) >= cstat) count++;
	}
	return ((double) count / num_B);
}



//calculate the distance-correlation-based test statistic for testing the independence of two vector-valued time series, where each is modeled through a flexible VAR model with B-splines
//(which is then estimated using the adaptive group LASSO). INPUT: a T0 by N_x matrix of data (obtained after re-centering by the unit-specific sample means) on the response of
//the first multivariate process (X), a T0 by N_y matrix of data (obtained after re-centering by the unit-specific sample means) on the response of the second multivariate process (Y),
//m*L_x*N_x by T0  and m*L_y*N_y by T0 matrices of B-spline basis functions evaluated at all the data points (BS_x and BS_y), m*L_x*N_x by N_x and m*L_y*N_y by N_y matrices
//of B-spline coefficients (beta_x and beta_y), and an exponent for the distance correlation (expn).
//OUTPUT: a double type value of the test statistic.
template <double kernel_k (double )>
double NGDist_corr::do_Test (const Matrix &X, const Matrix &Y, const Matrix &BS_x, const Matrix &BS_y, const Matrix &beta_x, const Matrix &beta_y, const int lag_smooth,
										   const double expn) {
	auto T0 = X.nRow(), N_x = X.nCol(), N_y = Y.nCol(), t = 1, s = 1, tau = 1, lag = 0;
	ASSERT (T0 == BS_x.nCol() && T0 == Y.nRow() && N_x == beta_x.nCol() &&  BS_x.nRow() == beta_x.nRow());
	ASSERT (T0 == BS_y.nCol() && N_y == beta_y.nCol() &&  BS_y.nRow() == beta_y.nRow());

	Matrix var_U_x(T0,T0), var_U_y(T0,T0);
	#pragma omp parallel sections num_threads(2)
	{
		#pragma omp section
		NGReg::var_U (var_U_x, X, BS_x, beta_x, expn); //calculate \H{U}_{t,s}^{(x)}, t = 1, ..., T0 and s = 1, ..., T0
		#pragma omp section
		NGReg::var_U (var_U_y, Y, BS_y, beta_y, expn); //calculate \H{U}_{t,s}^{(y)}, t = 1, ..., T0 and s = 1, ..., T0
	}

	double aVar = 0.;
	for (s = 1; s <= T0; s++) {
		for (t = s+1; t <= T0; t++) {
			aVar += ((double) 1/pow(T0, 2.)) * pow(var_U_x(t, s)*var_U_y(t, s), 2.);
		}
	}
	double weight = 0., sum1 = 0., sum2 = 0., sum3 = 0., sum4 = 0., cov = 0., sum = 0.;
	//prod_Var = var(X, TL, alpha(1), beta(1), lambda(1), sigma(1)) * var(Y, TL, alpha(2), beta(2), lambda(2), sigma(2));//calculate product of distance variances
	//cout << "product of variances = " << prod_Var << endl;
	#pragma omp parallel for default(shared) reduction (+:sum) schedule(dynamic,CHUNK) firstprivate(weight,sum1,sum2,sum3,sum4,cov) private(lag,t,s,tau)
	for (lag = 1-T0; lag <= T0-1; lag++) {
        if (lag == 0) weight = 1.;
        else weight = kernel_k ((double) lag/lag_smooth);
        if ((weight > 0.0001) || (weight < -0.0001)) {
        	if (lag >= 0) {
        	    sum1 = 0.;
        	    sum2 = 0.;
        	    sum3 = 0.;
        	    sum4 = 0.;
        	    for (t = lag+1; t <= T0; t++) {
			        for (s = lag+1; s <= T0; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t, s) * var_U_y(t-lag, s-lag);
				        }
				        sum3 += var_U_x(t, s);
				        sum4 += var_U_y(t-lag, s-lag) ;
				        for (tau = lag+1; tau <= T0; tau++) {
					        sum2 += 2 * var_U_x(t, s) * var_U_y(tau-lag, s-lag);
				        }
				    }
			    }
			    cov = ((double) 1/pow(T0-lag, 2.)) * sum1 - ((double) 1/pow(T0-lag, 3.)) * sum2 + ((double) 1/pow(T0-lag, 4.)) * sum3 * sum4;
		    }
		    else {
				sum1 = 0.;
				sum2 = 0.;
				sum3 = 0.;
				sum4 = 0.;
			    for (t = 1-lag; t <= T0; t++) {
			        for (s = 1-lag; s <= T0; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t+lag, s+lag) * var_U_y(t, s);
				        }
				        sum3 += var_U_x(t+lag, s+lag);
				        sum4 += var_U_y(t, s);
				        for (tau = 1-lag; tau <= T0; tau++) {
							sum2 += 2 * var_U_x(t+lag, s+lag) * var_U_y(t, tau);
				        }
			        }
		        }
			    cov = ((double) 1/pow(T0+lag, 2.)) * sum1 - ((double) 1/pow(T0+lag, 3.)) * sum2 + ((double) 1/pow(T0+lag, 4.)) * sum3 * sum4;
		    }
		    sum += T0 * pow(weight, 2.) * cov;
            //cout << "counting lags: " << lag << endl;
        }
	}
	auto kernel_QDSum = 0., kernel_QRSum = 0.;
	NGDist_corr::integrate_Kernel <kernel_k> (kernel_QDSum, kernel_QRSum);
	//cout << "sum = " << sum << endl;
	//return (sum - lag_smooth * kernel_QDSum * prod_Var) / (2 * sqrt(lag_smooth * kernel_QRSum * aVar));
	return sum / (2 * sqrt(lag_smooth * kernel_QRSum * aVar));
}

//calculate the bootstrap test statistics for two multivariate GARCH processes. INPUT: T-row matrices of data (X and Y), matrices of conditional means (cmean_X and cmean_Y),
//matrices of the sqrts of conditional variances and covariances (csigma_X and csigma_Y), matrices of GARCH residuals (resid_X and resid_Y), a lag-smoothing bandwidth (lag_smooth),
//num_BxT matrices of auxiliary random variables (xi_x and xi_y), an exponent for the Euclidean distance (expn in (1,2)), a kernel weight (kernel_k).
//OUTPUT: a bootstrap p-value, a value of the statistic (cstat), and a vector of bootstrap statistics (cstat_bootstrap)
template <double kernel_k (double )>
double NGDist_corr::calcul_Pvalue (double &cstat, Matrix &cstat_bootstrap, const Matrix &X, const Matrix &Y, const Matrix &cmean_X, const Matrix &cmean_Y,
												   const Matrix &csigma_X, const Matrix &csigma_Y, const Matrix &resid_X, const Matrix &resid_Y, const int lag_smooth,
												   const Matrix & xi_x, const Matrix &xi_y, const double expn) {
    auto t = 1, s = 1, tau = 1, lag = 0, i = 1;
    auto T0 = X.nRow();
    ASSERT (T0 == Y.nRow() &&  csigma_X.nCol() == X.nCol()*(X.nCol() + 1)/2 && csigma_Y.nCol() == Y.nCol()*(Y.nCol() + 1)/2) //check for the size consistency of data matrices
    auto num_B = xi_x.nRow();
    ASSERT (num_B == xi_y.nRow()); //check for the size consistency of matrices of auxiliary random variables

	Matrix var_U_x(T0, T0), var_U_y(T0, T0);
	NGReg::var_U (var_U_x, X, cmean_X, csigma_X, resid_X, expn);
	NGReg::var_U (var_U_y, Y, cmean_Y, csigma_Y, resid_Y, expn);



	double weight = 0., sum1 = 0., sum2 = 0., sum3 = 0., sum4 = 0., cov = 0., sum = 0.;
	//prod_Var = var(X, TL, alpha(1), beta(1), lambda(1), sigma(1)) * var(Y, TL, alpha(2), beta(2), lambda(2), sigma(2));//calculate product of distance variances
	//cout << "product of variances = " << prod_Var << endl;

	/* calculate the centered quantity */
	#pragma omp parallel for default(shared) reduction (+:sum) schedule(dynamic,CHUNK) firstprivate(weight,sum1,sum2,sum3,sum4,cov) private(lag,t,s,tau)
	for (lag = 1-T0; lag <= T0-1; lag++) {
        if (lag == 0) weight = 1.;
        else weight = kernel_k ((double) lag/lag_smooth);
        if ((weight > 0.0001) || (weight < -0.0001)) {
        	if (lag >= 0) {
        	    sum1 = 0.;
        	    sum2 = 0.;
        	    sum3 = 0.;
        	    sum4 = 0.;
        	    for (t = lag+1; t <= T0; t++) {
			        for (s = lag+1; s <= T0; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t, s) * var_U_y(t-lag, s-lag);
				        }
				        sum3 += var_U_x(t, s);
				        sum4 += var_U_y(t-lag, s-lag) ;
				        for (tau = lag+1; tau <= T0; tau++) {
					        sum2 += 2 * var_U_x(t, s) * var_U_y(tau-lag, s-lag);
				        }
				    }
			    }
			    cov = ((double) 1/pow(T0-lag, 2.)) * sum1 - ((double) 1/pow(T0-lag, 3.)) * sum2 + ((double) 1/pow(T0-lag, 4.)) * sum3 * sum4;
		    }
		    else {
				sum1 = 0.;
				sum2 = 0.;
				sum3 = 0.;
				sum4 = 0.;
			    for (t = 1-lag; t <= T0; t++) {
			        for (s = 1-lag; s <= T0; s++) {
			        	if (t != s) {
				            sum1 += var_U_x(t+lag, s+lag) * var_U_y(t, s);
				        }
				        sum3 += var_U_x(t+lag, s+lag);
				        sum4 += var_U_y(t, s);
				        for (tau = 1-lag; tau <= T0; tau++) {
					        sum2 += 2 * var_U_x(t+lag, s+lag) * var_U_y(t, tau);
				        }
			        }
		        }
			    cov = ((double) 1/pow(T0+lag, 2.)) * sum1 - ((double) 1/pow(T0+lag, 3.)) * sum2 + ((double) 1/pow(T0+lag, 4.)) * sum3 * sum4;
		    }
		    sum += T0 * pow(weight, 2.) * cov;
            //cout << "counting lags: " << lag << endl;
        }
	}
	//cout << "sum = " << sum << endl;
	//return (sum - lag_smooth * kernel_QDSum * prod_Var) / (2 * sqrt(lag_smooth * kernel_QRSum * aVar));
	cstat =  ((double) sum / sqrt(lag_smooth));
	//cout << "the value of the statistics = " << cstat << endl;

	/* calculate bootstrap centered quantities */
	#pragma omp parallel for default(shared) reduction (+:sum) schedule(dynamic,CHUNK) firstprivate(weight,sum1,sum2,sum3,sum4,cov) private(i,lag,t,s,tau)
	for (i = 1; i <= num_B; i++) {
		cov = 0.; //reset the value of 'cov' and 'sum' to zeros in each bootstrap iteration
		sum = 0.;
		for (lag = 1-T0; lag <= T0-1; lag++) {
			if (lag == 0) weight = 1.;
			else weight = kernel_k ((double) lag/lag_smooth);
			if ((weight > 0.0001) || (weight < -0.0001)) {
				if (lag >= 0) {
					sum1 = 0.;
					sum2 = 0.;
					sum3 = 0.;
					sum4 = 0.;
					for (t = lag+1; t <= T0; t++) {
						for (s = lag+1; s <= T0; s++) {
							if (t != s) {
								sum1 += xi_x(i, t) * xi_x(i, s) * var_U_x(t, s) * var_U_y(t-lag, s-lag) * xi_y(i, t-lag) * xi_y(i, s-lag);
							}
							sum3 += xi_x(i, t) * xi_x(i, s) * var_U_x(t, s);
							sum4 += xi_y(i, t-lag) * xi_y(i, s-lag) * var_U_y(t-lag, s-lag) ;
							for (tau = lag+1; tau <= T0; tau++) {
								sum2 += 2 * xi_x(i, t) * xi_x(i, s) * var_U_x(t, s) * var_U_y(tau-lag, s-lag) * xi_y(i, tau-lag) * xi_y(i, s-lag);
							}
						}
					}
					cov = ((double) 1/pow(T0-lag, 2.)) * sum1 - ((double) 1/pow(T0-lag, 3.)) * sum2 + ((double) 1/pow(T0-lag, 4.)) * sum3 * sum4;
				}
				else {
					sum1 = 0.;
					sum2 = 0.;
					sum3 = 0.;
					sum4 = 0.;
					for (t = 1-lag; t <= T0; t++) {
						for (s = 1-lag; s <= T0; s++) {
							if (t != s) {
								sum1 += xi_x(i, t+lag) * xi_x(i, s+lag) * var_U_x(t+lag, s+lag) * var_U_y(t, s) * xi_y(i, t) * xi_y(i, s);
							}
							sum3 += xi_x(i, t+lag) * xi_x(i, s+lag) * var_U_x(t+lag, s+lag);
							sum4 += xi_y(i, t) * xi_y(i, s) * var_U_y(t, s);
							for (tau = 1-lag; tau <= T0; tau++) {
								sum2 += 2 * xi_x(i, t+lag) * xi_x(i, s+lag) * var_U_x(t+lag, s+lag) * var_U_y(t, tau) * xi_y(i, t) * xi_y(i, tau);
							}
						}
					}
					cov = ((double) 1/pow(T0+lag, 2.)) * sum1 - ((double) 1/pow(T0+lag, 3.)) * sum2 + ((double) 1/pow(T0+lag, 4.)) * sum3 * sum4;
				}
				sum += T0 * pow(weight, 2.) * cov;
				//cout << "counting lags: " << lag << endl;
			}
		}
		cstat_bootstrap(i) =  ((double) sum / sqrt(lag_smooth));
	}

	int count = 0;
	for (i = 1; i <= num_B; i++) {
		if (cstat_bootstrap(i) >= cstat) count++;
	}
	return ((double) count / num_B);
}
















#endif
